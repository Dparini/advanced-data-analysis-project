{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Survival Analysis and Predictive Modeling\n",
    "\n",
    "**Objective**: Predict probability and timing of exit events (IPO, M&A) for VC-backed startups.\n",
    "\n",
    "**Methods**:\n",
    "1. Kaplan-Meier estimation\n",
    "2. Cox Proportional Hazards\n",
    "3. Competing Risks (Fine-Gray)\n",
    "4. Random Survival Forest\n",
    "5. Classification comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# Autoreload everything\n",
    "%autoreload 2\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter, WeibullAFTFitter\n",
    "from lifelines.statistics import logrank_test, multivariate_logrank_test\n",
    "from lifelines import AalenJohansenFitter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    brier_score_loss,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Configurazione paths\n",
    "\n",
    "# Crea directories\n",
    "config.OUTPUT_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.FINAL_PATH / 'finale_usa_cleaned.csv', low_memory=False)\n",
    "\n",
    "print(f'Shape: {df.shape}')\n",
    "print(f'Events: {df[\"event\"].sum()} / {len(df)} ({100*df[\"event\"].mean():.1f}%)')\n",
    "print(f'Duration: median={df[\"duration_years\"].median():.2f}, range=[{df[\"duration_years\"].min():.2f}, {df[\"duration_years\"].max():.2f}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_dist = df['event_type'].value_counts().sort_index()\n",
    "event_labels = {0: 'Censored', 1: 'IPO', 2: 'M&A', 3: 'Failure'}\n",
    "\n",
    "for idx, count in event_dist.items():\n",
    "    print(f'{event_labels[idx]}: {count} ({100*count/len(df):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC = ['log_fund_tot', 'funding_rounds', 'market_heat', 'relationships', \n",
    "           'milestones', 'angel', 'series_a', 'series_b', 'series_c', 'venture']\n",
    "\n",
    "CATEGORICAL = ['macro_settore', 'market_cycle']\n",
    "\n",
    "T = 'duration_years'\n",
    "E = 'event'\n",
    "E_TYPE = 'event_type'\n",
    "\n",
    "df_model = df[NUMERIC + CATEGORICAL + [T, E, E_TYPE]].copy()\n",
    "print(f'Model dataset: {df_model.shape}, missing: {df_model.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kaplan-Meier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(df_model[T], df_model[E], label='Overall')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "kmf.plot_survival_function(ax=ax, ci_show=True)\n",
    "ax.set_xlabel('Years from First Funding')\n",
    "ax.set_ylabel('Survival Probability')\n",
    "ax.set_title('Overall Survival Curve')\n",
    "ax.set_xlim(0, 15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Median survival: {kmf.median_survival_time_:.2f} years')\n",
    "for t in [1, 3, 5, 10]:\n",
    "    print(f'S({t}yr): {kmf.predict(t):.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "colors = {1: '#2ecc71', 2: '#3498db', 3: '#e74c3c'}\n",
    "labels = {1: 'IPO', 2: 'M&A', 3: 'Failure'}\n",
    "\n",
    "for etype in [1, 2, 3]:\n",
    "    mask = df_model[E_TYPE].isin([0, etype])\n",
    "    event_bin = (df_model.loc[mask, E_TYPE] == etype).astype(int)\n",
    "    kmf_sub = KaplanMeierFitter()\n",
    "    kmf_sub.fit(df_model.loc[mask, T], event_bin, label=labels[etype])\n",
    "    kmf_sub.plot_survival_function(ax=ax, ci_show=False, color=colors[etype])\n",
    "\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Survival Probability')\n",
    "ax.set_title('Survival by Exit Type')\n",
    "ax.set_xlim(0, 15)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_km_by_group(data, group_col, title):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for grp in sorted(data[group_col].dropna().unique()):\n",
    "        mask = data[group_col] == grp\n",
    "        kmf_g = KaplanMeierFitter()\n",
    "        kmf_g.fit(data.loc[mask, T], data.loc[mask, E], label=str(grp))\n",
    "        kmf_g.plot_survival_function(ax=ax, ci_show=False)\n",
    "    \n",
    "    ax.set_xlabel('Years')\n",
    "    ax.set_ylabel('Survival Probability')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(0, 15)\n",
    "    ax.legend(bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    result = multivariate_logrank_test(data[T], data[group_col], data[E])\n",
    "    print(f'Log-rank: chi2={result.test_statistic:.2f}, p={result.p_value:.2e}')\n",
    "    return result.p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sector = plot_km_by_group(df_model, 'macro_settore', 'Survival by Sector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cycle = plot_km_by_group(df_model, 'market_cycle', 'Survival by Market Cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['funding_q'] = pd.qcut(df_model['log_fund_tot'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "p_funding = plot_km_by_group(df_model, 'funding_q', 'Survival by Funding Quartile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrank_results = []\n",
    "\n",
    "test_vars = {\n",
    "    'macro_settore': df_model['macro_settore'],\n",
    "    'market_cycle': df_model['market_cycle'],\n",
    "    'funding_q': df_model['funding_q'],\n",
    "    'has_milestones': (df_model['milestones'] > 0).map({True: 'Yes', False: 'No'}),\n",
    "    'high_network': (df_model['relationships'] > df_model['relationships'].median()).map({True: 'High', False: 'Low'})\n",
    "}\n",
    "\n",
    "for name, var in test_vars.items():\n",
    "    res = multivariate_logrank_test(df_model[T], var, df_model[E])\n",
    "    logrank_results.append({'Variable': name, 'Chi2': res.test_statistic, \n",
    "                            'p_value': res.p_value, 'Sig': res.p_value < 0.05})\n",
    "\n",
    "lr_df = pd.DataFrame(logrank_results).sort_values('p_value')\n",
    "print(lr_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cox Proportional Hazards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox = df_model.drop(columns=['funding_q']).copy()\n",
    "df_cox = pd.get_dummies(df_cox, columns=CATEGORICAL, drop_first=True)\n",
    "print(f'Cox dataset: {df_cox.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df_cox.columns if c not in [T, E, E_TYPE]]\n",
    "uni_results = []\n",
    "\n",
    "for feat in features:\n",
    "    try:\n",
    "        cph_u = CoxPHFitter()\n",
    "        cph_u.fit(df_cox[[T, E, feat]], duration_col=T, event_col=E)\n",
    "        s = cph_u.summary\n",
    "        uni_results.append({\n",
    "            'Feature': feat,\n",
    "            'HR': s.loc[feat, 'exp(coef)'],\n",
    "            'CI_low': s.loc[feat, 'exp(coef) lower 95%'],\n",
    "            'CI_high': s.loc[feat, 'exp(coef) upper 95%'],\n",
    "            'p': s.loc[feat, 'p']\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "uni_df = pd.DataFrame(uni_results).sort_values('p')\n",
    "print('Univariate Cox (top 15):')\n",
    "print(uni_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph = CoxPHFitter(penalizer=0.01)\n",
    "cph.fit(df_cox.drop(columns=['event_type']), duration_col=T, event_col=E)\n",
    "\n",
    "print(f'C-index: {cph.concordance_index_:.4f}')\n",
    "print(f'LR test p-value: {cph.log_likelihood_ratio_test().p_value:.2e}')\n",
    "print('\\nSignificant (p<0.05):')\n",
    "sig = cph.summary[cph.summary['p'] < 0.05][['exp(coef)', 'p']].round(4)\n",
    "print(sig.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.statistics import proportional_hazard_test\n",
    "\n",
    "ph_test = proportional_hazard_test(cph, df_cox.drop(columns=['event_type']), time_transform='rank')\n",
    "print(\"Test Proportional Hazards:\")\n",
    "print(ph_test.summary)\n",
    "\n",
    "cph.check_assumptions(df_cox.drop(columns=['event_type']), p_value_threshold=0.05, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cph.plot(ax=ax, hazard_ratios=True)\n",
    "ax.axvline(x=1, color='black', linestyle=':', alpha=0.5)\n",
    "ax.set_title('Hazard Ratios (95% CI)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_test = cph.check_assumptions(df_cox.drop(columns=[E_TYPE]), p_value_threshold=0.05, show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cph.plot_partial_effects_on_outcome('log_fund_tot', values=[10, 13, 16, 19], ax=ax, cmap='coolwarm')\n",
    "ax.set_title('Survival by Funding Level')\n",
    "ax.set_xlim(0, 15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Competing Risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajf = AalenJohansenFitter()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "colors = {1: '#2ecc71', 2: '#3498db', 3: '#e74c3c'}\n",
    "labels = {1: 'IPO', 2: 'M&A', 3: 'Failure'}\n",
    "\n",
    "for ecode in [1, 2, 3]:\n",
    "    ajf.fit(df_model[T], df_model[E_TYPE], event_of_interest=ecode)\n",
    "    ajf.plot(ax=ax, label=labels[ecode], color=colors[ecode])\n",
    "\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Cumulative Incidence')\n",
    "ax.set_title('Cumulative Incidence Functions')\n",
    "ax.set_xlim(0, 15)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cumulative incidence at 5 years:')\n",
    "for ecode in [1, 2, 3]:\n",
    "    ajf.fit(df_model[T], df_model[E_TYPE], event_of_interest=ecode)\n",
    "    ci = ajf.predict(5)\n",
    "    print(f'  {labels[ecode]}: {ci:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fine-Gray Subdistribution Hazards')\n",
    "\n",
    "def prepare_fine_gray_data(df, event_of_interest):\n",
    "    df_fg = df.copy()\n",
    "    df_fg['E_cr'] = (df_fg[E_TYPE] == event_of_interest).astype(int)\n",
    "    return df_fg\n",
    "\n",
    "df_fg_ipo = prepare_fine_gray_data(df_cox, 1)\n",
    "df_fg_ma = prepare_fine_gray_data(df_cox, 2)\n",
    "df_fg_fail = prepare_fine_gray_data(df_cox, 3)\n",
    "\n",
    "feat_cols = [c for c in df_cox.columns if c not in [T, E, E_TYPE]]\n",
    "\n",
    "print('IPO Subdistribution Model:')\n",
    "cph_ipo_sub = CoxPHFitter(penalizer=0.01)\n",
    "cph_ipo_sub.fit(df_fg_ipo[feat_cols + [T, 'E_cr']], duration_col=T, event_col='E_cr')\n",
    "print(f'C-index: {cph_ipo_sub.concordance_index_:.4f}')\n",
    "print(cph_ipo_sub.summary[cph_ipo_sub.summary['p'] < 0.05][['exp(coef)', 'p']].head())\n",
    "\n",
    "print('\\nM&A Subdistribution Model:')\n",
    "cph_ma_sub = CoxPHFitter(penalizer=0.01)\n",
    "cph_ma_sub.fit(df_fg_ma[feat_cols + [T, 'E_cr']], duration_col=T, event_col='E_cr')\n",
    "print(f'C-index: {cph_ma_sub.concordance_index_:.4f}')\n",
    "print(cph_ma_sub.summary[cph_ma_sub.summary['p'] < 0.05][['exp(coef)', 'p']].head())\n",
    "\n",
    "print('\\nFailure Subdistribution Model:')\n",
    "cph_fail_sub = CoxPHFitter(penalizer=0.01)\n",
    "cph_fail_sub.fit(df_fg_fail[feat_cols + [T, 'E_cr']], duration_col=T, event_col='E_cr')\n",
    "print(f'C-index: {cph_fail_sub.concordance_index_:.4f}')\n",
    "print(cph_fail_sub.summary[cph_fail_sub.summary['p'] < 0.05][['exp(coef)', 'p']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cause_specific_cox(data, cause, feat_cols):\n",
    "    df_c = data.copy()\n",
    "    df_c['e_cause'] = (df_c[E_TYPE] == cause).astype(int)\n",
    "    df_c = df_c[df_c[E_TYPE].isin([0, cause])]\n",
    "    \n",
    "    cph_c = CoxPHFitter(penalizer=0.01)\n",
    "    cph_c.fit(df_c[feat_cols + [T, 'e_cause']], duration_col=T, event_col='e_cause')\n",
    "    return cph_c\n",
    "\n",
    "feat_cols = [c for c in df_cox.columns if c not in [T, E, E_TYPE]]\n",
    "df_cr = df_cox.copy()\n",
    "df_cr[E_TYPE] = df_model[E_TYPE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_ipo = cause_specific_cox(df_cr, 1, feat_cols)\n",
    "print(f'IPO model C-index: {cph_ipo.concordance_index_:.4f}')\n",
    "print(cph_ipo.summary[cph_ipo.summary['p'] < 0.1][['exp(coef)', 'p']].round(4).head(8).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_ma = cause_specific_cox(df_cr, 2, feat_cols)\n",
    "print(f'M&A model C-index: {cph_ma.concordance_index_:.4f}')\n",
    "print(cph_ma.summary[cph_ma.summary['p'] < 0.05][['exp(coef)', 'p']].round(4).head(8).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_fail = cause_specific_cox(df_cr, 3, feat_cols)\n",
    "print(f'Failure model C-index: {cph_fail.concordance_index_:.4f}')\n",
    "print(cph_fail.summary[cph_fail.summary['p'] < 0.05][['exp(coef)', 'p']].round(4).head(8).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_feats = ['log_fund_tot', 'funding_rounds', 'market_heat', 'relationships', 'milestones']\n",
    "comp_data = []\n",
    "\n",
    "for f in compare_feats:\n",
    "    row = {'Feature': f}\n",
    "    for model, name in [(cph_ipo, 'IPO'), (cph_ma, 'M&A'), (cph_fail, 'Fail')]:\n",
    "        if f in model.summary.index:\n",
    "            row[name] = model.summary.loc[f, 'exp(coef)']\n",
    "    comp_data.append(row)\n",
    "\n",
    "print('HR comparison by outcome:')\n",
    "print(pd.DataFrame(comp_data).round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning: Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cox.drop(columns=[T, E, E_TYPE])\n",
    "y_surv = Surv.from_dataframe(E, T, df_cox)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_surv, test_size=0.2, random_state=SEED)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns, index=X_train.index)\n",
    "X_test_s = pd.DataFrame(scaler.transform(X_test), columns=X.columns, index=X_test.index)\n",
    "\n",
    "print(f'Train: {len(X_train)}, Test: {len(X_test)}')\n",
    "print(f'Event rate: train={y_train[E].mean():.2%}, test={y_test[E].mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf = RandomSurvivalForest(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=15,\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED\n",
    ")\n",
    "rsf.fit(X_train_s, y_train)\n",
    "\n",
    "ci_rsf_train = rsf.score(X_train_s, y_train)\n",
    "ci_rsf_test = rsf.score(X_test_s, y_test)\n",
    "\n",
    "print(f'RSF C-index: train={ci_rsf_train:.4f}, test={ci_rsf_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import brier_score\n",
    "\n",
    "times = np.percentile(df_cox[df_cox[E] == 1][T], np.linspace(10, 90, 9))\n",
    "max_time = min(y_test[T].max(), rsf.unique_times_.max())\n",
    "times = times[times < max_time]\n",
    "\n",
    "surv_funcs_full = rsf.predict_survival_function(X_test_s, return_array=True)\n",
    "\n",
    "surv_funcs_at_times = np.zeros((len(X_test_s), len(times)))\n",
    "for i, t in enumerate(times):\n",
    "    time_idx = np.searchsorted(rsf.unique_times_, t)\n",
    "    if time_idx >= len(rsf.unique_times_):\n",
    "        time_idx = len(rsf.unique_times_) - 1\n",
    "    surv_funcs_at_times[:, i] = surv_funcs_full[:, time_idx]\n",
    "\n",
    "brier_scores = []\n",
    "for i, t in enumerate(times):\n",
    "    _, bs = brier_score(y_train, y_test, surv_funcs_at_times[:, i], t)\n",
    "    brier_scores.append(bs[0])\n",
    "\n",
    "ibs = np.trapezoid(brier_scores, times) / (times[-1] - times[0])\n",
    "\n",
    "print(f'Integrated Brier Score: {ibs:.4f}')\n",
    "print(f'Mean Brier Score: {np.mean(brier_scores):.4f}')\n",
    "print(f'Brier at each time:')\n",
    "for t, bs in zip(times, brier_scores):\n",
    "    print(f'  {t:.1f} years: {bs:.4f}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, brier_scores, 'o-', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Time (years)')\n",
    "ax.set_ylabel('Brier Score')\n",
    "ax.set_title('Brier Score over Time (RSF)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "t_eval = 5\n",
    "time_idx_5y = np.searchsorted(rsf.unique_times_, t_eval)\n",
    "if time_idx_5y >= len(rsf.unique_times_):\n",
    "    time_idx_5y = len(rsf.unique_times_) - 1\n",
    "\n",
    "surv_funcs_full = rsf.predict_survival_function(X_test_s, return_array=True)\n",
    "risk_pred_5y = 1 - surv_funcs_full[:, time_idx_5y]\n",
    "y_obs_5y = (y_test[T] <= t_eval) & (y_test[E])\n",
    "\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "    y_obs_5y, risk_pred_5y, n_bins=8, strategy='quantile'\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.plot(mean_predicted_value, fraction_of_positives, 'o-', linewidth=2, \n",
    "        markersize=8, label='RSF')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Perfect Calibration')\n",
    "ax.set_xlabel('Predicted Risk at 5 Years')\n",
    "ax.set_ylabel('Observed Event Rate')\n",
    "ax.set_title('Calibration Plot (5-year Risk)')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 0.35)\n",
    "ax.set_ylim(0, 0.35)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean absolute calibration error: {np.mean(np.abs(fraction_of_positives - mean_predicted_value)):.4f}')\n",
    "print(f'Bins: {len(fraction_of_positives)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "times_eval = np.array([1, 3, 5, 10])\n",
    "\n",
    "risk_test = rsf.predict(X_test_s)\n",
    "\n",
    "auc_scores = []\n",
    "for t in times_eval:\n",
    "    mask = (y_test[T] >= t) | (y_test[E] == True)\n",
    "    if mask.sum() < 10:\n",
    "        auc_scores.append(np.nan)\n",
    "        continue\n",
    "    \n",
    "    y_test_t = y_test[mask]\n",
    "    risk_t = risk_test[mask]\n",
    "    \n",
    "    event_t = (y_test_t[T] <= t) & (y_test_t[E] == True)\n",
    "    \n",
    "    try:\n",
    "        ci, _, _, _, _ = concordance_index_censored(event_t, y_test_t[T], risk_t)\n",
    "        auc_scores.append(ci)\n",
    "    except:\n",
    "        auc_scores.append(np.nan)\n",
    "\n",
    "auc_scores = np.array(auc_scores)\n",
    "mean_auc = np.nanmean(auc_scores)\n",
    "\n",
    "print('Time-Dependent AUC (C-index):')\n",
    "for t, auc in zip(times_eval, auc_scores):\n",
    "    print(f'  {t} year(s): {auc:.4f}')\n",
    "print(f'Mean: {mean_auc:.4f}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times_eval, auc_scores, 'o-', linewidth=2, markersize=8)\n",
    "ax.axhline(y=0.5, color='k', linestyle='--', alpha=0.5, label='Random')\n",
    "ax.set_xlabel('Time (years)')\n",
    "ax.set_ylabel('C-index')\n",
    "ax.set_title('Discrimination Performance over Time (RSF)')\n",
    "ax.set_ylim([0.4, 1.0])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calcola permutation importance\n",
    "perm_importance = permutation_importance(rsf, X_test_s, y_test, n_repeats=10, random_state=SEED, n_jobs=1)\n",
    "\n",
    "rsf_imp = pd.DataFrame({'Feature': X.columns, 'Importance': perm_importance.importances_mean})\n",
    "rsf_imp = rsf_imp.sort_values('Importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top = rsf_imp.head(15)\n",
    "ax.barh(range(len(top)), top['Importance'].values, color='blue')\n",
    "ax.set_yticks(range(len(top)))\n",
    "ax.set_yticklabels(top['Feature'].values)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('RSF Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "import matplotlib.image\n",
    "from pathlib import Path\n",
    "\n",
    "rf_for_tree = RandomForestClassifier(n_estimators=10, max_depth=5, random_state=SEED, n_jobs=-1)\n",
    "rf_for_tree.fit(X_train_s, y_train[E])\n",
    "\n",
    "tree_idx = 3\n",
    "estimator = rf_for_tree.estimators_[tree_idx]\n",
    "\n",
    "dot_file = config.OUTPUT_PATH / 'tree.dot'\n",
    "png_file = config.OUTPUT_PATH /  'tree.png'\n",
    "\n",
    "export_graphviz(estimator, \n",
    "                out_file=str(dot_file),\n",
    "                feature_names=X.columns.tolist(),\n",
    "                class_names=['Censored', 'Event'],\n",
    "                rounded=True, \n",
    "                proportion=False,\n",
    "                precision=2, \n",
    "                filled=True)\n",
    "\n",
    "call(['dot', '-Tpng', str(dot_file), '-o', str(png_file), '-Gdpi=600'])\n",
    "\n",
    "img = matplotlib.image.imread(str(png_file))\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(f'Random Forest - Tree {tree_idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Saved to: {png_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bootstrap Confidence Intervals')\n",
    "\n",
    "n_bootstrap = 100\n",
    "bootstrap_preds = []\n",
    "\n",
    "sample_idx = 0\n",
    "X_sample = X_test_s.iloc[[sample_idx]]\n",
    "\n",
    "for i in range(n_bootstrap):\n",
    "    idx = np.random.choice(len(X_train_s), len(X_train_s), replace=True)\n",
    "    X_boot = X_train_s.iloc[idx]\n",
    "    y_boot = y_train[idx]\n",
    "    \n",
    "    rsf_boot = RandomSurvivalForest(\n",
    "        n_estimators=50, \n",
    "        max_depth=5,\n",
    "        random_state=i,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rsf_boot.fit(X_boot, y_boot)\n",
    "    \n",
    "    surv = rsf_boot.predict_survival_function(X_sample, return_array=True)\n",
    "    time_idx = np.searchsorted(rsf_boot.unique_times_, 5)\n",
    "    time_idx = min(time_idx, len(rsf_boot.unique_times_) - 1)\n",
    "    risk = 1 - surv[0, time_idx]\n",
    "    bootstrap_preds.append(risk)\n",
    "\n",
    "pred_mean = np.mean(bootstrap_preds)\n",
    "pred_ci = np.percentile(bootstrap_preds, [2.5, 97.5])\n",
    "\n",
    "print(f'Sample {sample_idx} - 5-year Risk:')\n",
    "print(f'Point estimate: {pred_mean:.3f}')\n",
    "print(f'95% CI: [{pred_ci[0]:.3f}, {pred_ci[1]:.3f}]')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.hist(bootstrap_preds, bins=30, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(pred_mean, color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "ax.axvline(pred_ci[0], color='orange', linestyle=':', linewidth=2, label='95% CI')\n",
    "ax.axvline(pred_ci[1], color='orange', linestyle=':', linewidth=2)\n",
    "ax.set_xlabel('Predicted 5-year Risk')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Bootstrap Distribution of Risk Prediction')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from xgbse import XGBSEKaplanNeighbors\n",
    "    from xgbse.converters import convert_to_structured\n",
    "    \n",
    "    y_train_xgb = convert_to_structured(df_cox.loc[X_train.index, T], df_cox.loc[X_train.index, E])\n",
    "    y_test_xgb = convert_to_structured(df_cox.loc[X_test.index, T], df_cox.loc[X_test.index, E])\n",
    "    \n",
    "    xgbse = XGBSEKaplanNeighbors(\n",
    "        n_neighbors=50,\n",
    "        xgb_params={\n",
    "            'objective': 'survival:aft',\n",
    "            'eval_metric': 'aft-nloglik',\n",
    "            'aft_loss_distribution': 'normal',\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 5,\n",
    "            'learning_rate': 0.1,\n",
    "            'random_state': SEED,\n",
    "            'n_jobs': 1 #Disk full\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    xgbse.fit(\n",
    "        X_train_s, \n",
    "        y_train_xgb,\n",
    "        num_boost_round=100,\n",
    "        validation_data=(X_test_s, y_test_xgb),\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    \n",
    "    risk_test = -xgbse.predict(X_test_s).mean(axis=1)\n",
    "\n",
    "    ci_xgb_test = concordance_index_censored(\n",
    "        y_test_xgb[y_test_xgb.dtype.names[0]],\n",
    "        y_test_xgb[y_test_xgb.dtype.names[1]],\n",
    "        risk_test\n",
    "    )[0]\n",
    "    \n",
    "    print(f'XGBSE C-index: test={ci_xgb_test:.4f}')\n",
    "    \n",
    "except ImportError:\n",
    "    print('XGBSE not installed, skipping')\n",
    "    ci_xgb_test = None\n",
    "except Exception as e:\n",
    "    print(f'XGBSE error: {e}')\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    ci_xgb_test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox_test = df_cox.loc[X_test.index]\n",
    "cph_pred = cph.predict_partial_hazard(X_test)\n",
    "ci_cox = concordance_index_censored(df_cox_test[E].astype(bool), df_cox_test[T], cph_pred)[0]\n",
    "\n",
    "print('Model Comparison (C-index, test):')\n",
    "print(f'Cox PH: {ci_cox:.4f}')\n",
    "print(f'RSF: {ci_rsf_test:.4f}')\n",
    "if ci_xgb_test:\n",
    "    print(f'XGBSE: {ci_xgb_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_cox.copy()\n",
    "df_class['outcome'] = df_model[E_TYPE].map({0: 'Censored', 1: 'Exit', 2: 'Exit', 3: 'Failure'})\n",
    "df_class = df_class[df_class['outcome'] != 'Censored'].copy()\n",
    "df_class['y'] = (df_class['outcome'] == 'Exit').astype(int)\n",
    "\n",
    "print(f'Classification set: {len(df_class)}')\n",
    "print(df_class['outcome'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = df_class.drop(columns=[T, E, E_TYPE, 'outcome', 'y'])\n",
    "y_c = df_class['y']\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_c, y_c, test_size=0.2, random_state=SEED, stratify=y_c)\n",
    "\n",
    "scaler_c = StandardScaler()\n",
    "X_tr_s = scaler_c.fit_transform(X_tr)\n",
    "X_te_s = scaler_c.transform(X_te)\n",
    "\n",
    "print(f'Train: {len(X_tr)}, Test: {len(X_te)}, Exit rate: {y_tr.mean():.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_clf(model, X_tr, X_te, y_tr, y_te, name):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "    y_prob = model.predict_proba(X_te)[:, 1]\n",
    "    \n",
    "    res = {\n",
    "        'Model': name,\n",
    "        'Acc': accuracy_score(y_te, y_pred),\n",
    "        'Prec': precision_score(y_te, y_pred),\n",
    "        'Rec': recall_score(y_te, y_pred),\n",
    "        'F1': f1_score(y_te, y_pred),\n",
    "        'AUC': roc_auc_score(y_te, y_prob)\n",
    "    }\n",
    "    return res, y_prob, confusion_matrix(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=100, random_state=SEED, n_jobs=-1)\n",
    "res1, prob1, cm1 = eval_clf(rf1, X_tr_s, X_te_s, y_tr, y_te, 'RF Unbalanced')\n",
    "\n",
    "print(f'{res1[\"Model\"]}: Acc={res1[\"Acc\"]:.3f}, Prec={res1[\"Prec\"]:.3f}, Rec={res1[\"Rec\"]:.3f}, F1={res1[\"F1\"]:.3f}, AUC={res1[\"AUC\"]:.3f}')\n",
    "print(f'Confusion matrix:\\n{cm1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=SEED, n_jobs=-1)\n",
    "res2, prob2, cm2 = eval_clf(rf2, X_tr_s, X_te_s, y_tr, y_te, 'RF Balanced')\n",
    "\n",
    "print(f'{res2[\"Model\"]}: Acc={res2[\"Acc\"]:.3f}, Prec={res2[\"Prec\"]:.3f}, Rec={res2[\"Rec\"]:.3f}, F1={res2[\"F1\"]:.3f}, AUC={res2[\"AUC\"]:.3f}')\n",
    "print(f'Confusion matrix:\\n{cm2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=SEED)\n",
    "res3, prob3, cm3 = eval_clf(gb, X_tr_s, X_te_s, y_tr, y_te, 'GradientBoosting')\n",
    "\n",
    "print(f'{res3[\"Model\"]}: Acc={res3[\"Acc\"]:.3f}, Prec={res3[\"Prec\"]:.3f}, Rec={res3[\"Rec\"]:.3f}, F1={res3[\"F1\"]:.3f}, AUC={res3[\"AUC\"]:.3f}')\n",
    "print(f'Confusion matrix:\\n{cm3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [10, 20],\n",
    "    'min_samples_leaf': [5, 10]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestClassifier(class_weight='balanced', random_state=SEED, n_jobs=-1),\n",
    "    param_grid, cv=5, scoring='f1', n_jobs=-1\n",
    ")\n",
    "grid.fit(X_tr_s, y_tr)\n",
    "\n",
    "print(f'Best params: {grid.best_params_}')\n",
    "print(f'Best CV F1: {grid.best_score_:.4f}')\n",
    "\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_rf.predict(X_tr_s)\n",
    "y_pred_test = best_rf.predict(X_te_s)\n",
    "\n",
    "print(f'Train F1: {f1_score(y_tr, y_pred_train):.4f}')\n",
    "print(f'Test F1: {f1_score(y_te, y_pred_test):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid.best_estimator_\n",
    "res_best, prob_best, cm_best = eval_clf(best_rf, X_tr_s, X_te_s, y_tr, y_te, 'RF Tuned')\n",
    "\n",
    "print(f'{res_best[\"Model\"]}: Acc={res_best[\"Acc\"]:.3f}, Prec={res_best[\"Prec\"]:.3f}, Rec={res_best[\"Rec\"]:.3f}, F1={res_best[\"F1\"]:.3f}, AUC={res_best[\"AUC\"]:.3f}')\n",
    "print(f'Confusion matrix:\\n{cm_best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "prec, rec, thresholds = precision_recall_curve(y_te, prob_best)\n",
    "f1_scores = 2 * prec[:-1] * rec[:-1] / (prec[:-1] + rec[:-1] + 1e-8)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[best_idx]\n",
    "\n",
    "axes[0].plot(rec, prec, 'b-', lw=2)\n",
    "axes[0].scatter([rec[best_idx]], [prec[best_idx]], color='red', s=100, zorder=5)\n",
    "axes[0].set_xlabel('Recall')\n",
    "axes[0].set_ylabel('Precision')\n",
    "axes[0].set_title(f'PR Curve (best threshold={best_thresh:.2f})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_te, prob_best)\n",
    "auc = roc_auc_score(y_te, prob_best)\n",
    "axes[1].plot(fpr, tpr, 'b-', lw=2, label=f'AUC={auc:.3f}')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "axes[1].set_xlabel('FPR')\n",
    "axes[1].set_ylabel('TPR')\n",
    "axes[1].set_title('ROC Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Optimal threshold: {best_thresh:.4f}')\n",
    "print(f'At threshold: Prec={prec[best_idx]:.3f}, Rec={rec[best_idx]:.3f}, F1={f1_scores[best_idx]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_results = pd.DataFrame([res1, res2, res3, res_best])\n",
    "print('Classification Model Comparison:')\n",
    "print(clf_results.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "models = {\n",
    "    'RF Unbalanced': rf1,\n",
    "    'RF Balanced': rf2,\n",
    "    'Gradient Boosting': gb,\n",
    "    'RF Tuned': best_rf\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(name.upper())\n",
    "    \n",
    "    y_pred = model.predict(X_te_s)\n",
    "    \n",
    "    f1 = f1_score(y_te, y_pred, average='macro')\n",
    "    \n",
    "    print(f'Precision:{precision_score(y_te, y_pred):.4f}')\n",
    "    print(f'Recall:{recall_score(y_te, y_pred):.4f}')\n",
    "    print(f'F1 Score:{f1:.4f}')\n",
    "    print(f'\\nReport:\\n{classification_report(y_te, y_pred, digits=4)}')\n",
    "    \n",
    "    cm = confusion_matrix(y_te, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',\n",
    "                xticklabels=['Censored', 'Event'],\n",
    "                yticklabels=['Censored', 'Event'],\n",
    "                annot_kws={'size': 16, 'weight': 'bold'},\n",
    "                linewidths=0,\n",
    "                linecolor='white',\n",
    "                cbar=True,\n",
    "                ax=ax)\n",
    "    ax.set_xlabel('Predicted label', fontsize=12)\n",
    "    ax.set_ylabel('True label', fontsize=12)\n",
    "    ax.set_title(f'Confusion Matrix - {name}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('_' * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cox_imp = cph.summary['coef'].abs()\n",
    "cox_imp = cox_imp / cox_imp.max()\n",
    "\n",
    "rsf_imp_s = rsf_imp.set_index('Feature')['Importance']\n",
    "rsf_imp_s = rsf_imp_s / rsf_imp_s.max()\n",
    "\n",
    "rf_imp = pd.Series(best_rf.feature_importances_, index=X_c.columns)\n",
    "rf_imp = rf_imp / rf_imp.max()\n",
    "\n",
    "imp_df = pd.DataFrame({'Cox': cox_imp, 'RSF': rsf_imp_s, 'RF': rf_imp}).fillna(0)\n",
    "imp_df['Avg'] = imp_df.mean(axis=1)\n",
    "imp_df = imp_df.sort_values('Avg', ascending=False)\n",
    "\n",
    "print('Feature Importance (normalized):')\n",
    "print(imp_df.head(12).round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "top_f = imp_df.head(12).index\n",
    "plot_d = imp_df.loc[top_f, ['Cox', 'RSF', 'RF']]\n",
    "x = np.arange(len(top_f))\n",
    "w = 0.25\n",
    "\n",
    "ax.barh(x - w, plot_d['Cox'], w, label='Cox PH', color='#3498db')\n",
    "ax.barh(x, plot_d['RSF'], w, label='RSF', color='#2ecc71')\n",
    "ax.barh(x + w, plot_d['RF'], w, label='RF Class', color='#e74c3c')\n",
    "\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(top_f)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Normalized Importance')\n",
    "ax.set_title('Feature Importance Comparison')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(f'\\nDATASET')\n",
    "print(f'- IPO: {(df[E_TYPE]==1).sum()}')\n",
    "print(f'- M&A: {(df[E_TYPE]==2).sum()}')\n",
    "print(f'- Failure: {(df[E_TYPE]==3).sum()}')\n",
    "\n",
    "print(f'\\nSURVIVAL MODELS (C-index)')\n",
    "print(f'- Cox PH: {ci_cox:.4f}')\n",
    "print(f'- RSF: {ci_rsf_test:.4f}')\n",
    "if 'ci_xgb_test' in locals() and ci_xgb_test:\n",
    "    print(f'- XGBSE: {ci_xgb_test:.4f}')\n",
    "\n",
    "print(f'\\nMODEL CALIBRATION')\n",
    "print(f'- Integrated Brier Score: {ibs:.4f}')\n",
    "print(f'- Mean Calibration Error (5y): {np.mean(np.abs(fraction_of_positives - mean_predicted_value)):.4f}')\n",
    "\n",
    "print(f'\\nCLASSIFICATION (Best Model: {res_best[\"Model\"]})')\n",
    "print(f'- F1: {res_best[\"F1\"]:.4f}')\n",
    "print(f'- AUC: {res_best[\"AUC\"]:.4f}')\n",
    "\n",
    "print(f'\\nTOP FEATURES')\n",
    "for i, (f, _) in enumerate(imp_df.head(5).iterrows(), 1):\n",
    "    print(f'{i}. {f}')\n",
    "\n",
    "results = {\n",
    "    'survival': {'cox': ci_cox, 'rsf': ci_rsf_test, 'xgbse': ci_xgb_test if 'ci_xgb_test' in locals() else None},\n",
    "    'calibration': {'ibs': ibs, 'brier_mean': np.mean(brier_scores)},\n",
    "    'classification': clf_results.to_dict('records'),\n",
    "    'feature_importance': imp_df.head(10).to_dict(),\n",
    "    'n_samples': len(df),\n",
    "    'n_events': int(df[E].sum())\n",
    "}\n",
    "\n",
    "config.OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataset_path = config.OUTPUT_PATH / 'finale_usa_cleaned.csv'\n",
    "df.to_csv(dataset_path, index=False)\n",
    "print(f'\\nDATASET SAVED: {dataset_path}')\n",
    "\n",
    "results_path = config.OUTPUT_PATH / 'model_results.json'\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(f'\\nRESULTS SAVED: {results_path}')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
